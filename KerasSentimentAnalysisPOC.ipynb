{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exacon03/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants, signature_def_utils_impl\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif,chi2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exacon03/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "training = np.genfromtxt('/home/exacon03/Downloads/Sentiment Analysis Dataset.csv', delimiter=',', skip_header=1, usecols=(1, 3), dtype=None,max_rows=100000)\n",
    "\n",
    "train_x = [x[1] for x in training]\n",
    "train_y = np.asarray([x[0] for x in training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_for_production(model, version, path='prod_models'):\n",
    "    tf.keras.backend.set_learning_phase(1)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    export_path = os.path.join(\n",
    "        tf.compat.as_bytes(path),\n",
    "        tf.compat.as_bytes(version))\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "\n",
    "    model_input = tf.saved_model.utils.build_tensor_info(model.input)\n",
    "    model_output = tf.saved_model.utils.build_tensor_info(model.output)\n",
    "\n",
    "    prediction_signature = (\n",
    "        tf.saved_model.signature_def_utils.build_signature_def(\n",
    "            inputs={'inputs': model_input},\n",
    "            outputs={'output': model_output},\n",
    "            method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "    with tf.keras.backend.get_session() as sess:\n",
    "        builder.add_meta_graph_and_variables(\n",
    "            sess=sess, tags=[tf.saved_model.tag_constants.SERVING],\n",
    "            signature_def_map={\n",
    "                signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:prediction_signature,\n",
    "            })\n",
    "\n",
    "        builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(layers, units, dropout_rate, input_shape, num_classes):\n",
    "    \"\"\"Creates an instance of a multi-layer perceptron model.\n",
    "\n",
    "    # Arguments\n",
    "        layers: int, number of `Dense` layers in the model.\n",
    "        units: int, output dimension of the layers.\n",
    "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
    "        input_shape: tuple, shape of input to the model.\n",
    "        num_classes: int, number of output classes.\n",
    "\n",
    "    # Returns\n",
    "        An MLP model instance.\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(units=units, activation='relu'))\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
    "kwargs = {\n",
    "            'ngram_range': (1,2),  # Use 1-grams + 2-grams.\n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': 'word',  # Split text into word tokens.\n",
    "            'min_df':  2,\n",
    "}\n",
    "vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "# Learn vocabulary from training texts and vectorize training texts.\n",
    "train_x = vectorizer.fit_transform(train_x)\n",
    "\n",
    "# print(type(train_x))\n",
    "\n",
    "# Select top 'k' of the vectorized features.\n",
    "selector = SelectKBest(chi2, k=min(20000, train_x.shape[1]))\n",
    "train_x = selector.fit_transform(train_x, train_y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameters for the model\n",
    "layers=2\n",
    "units=32\n",
    "learning_rate=1e-3\n",
    "dropout_rate=0.2\n",
    "input_shape=train_x.shape[1:]\n",
    "num_classes=2\n",
    "\n",
    "\n",
    "# Create model instance.\n",
    "model=mlp_model(layers,units,dropout_rate,input_shape,num_classes)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "  optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "80000/80000 [==============================] - 14s 176us/step - loss: 0.3658 - acc: 0.8233 - val_loss: 0.4226 - val_acc: 0.8087\n",
      "Epoch 2/20\n",
      "80000/80000 [==============================] - 14s 175us/step - loss: 0.3634 - acc: 0.8250 - val_loss: 0.4218 - val_acc: 0.8094\n",
      "Epoch 3/20\n",
      "80000/80000 [==============================] - 14s 178us/step - loss: 0.3587 - acc: 0.8252 - val_loss: 0.4222 - val_acc: 0.8103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa3b2d67208>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and validate model.\n",
    "model.fit(train_x, train_y,\n",
    "  batch_size=512,\n",
    "  epochs=20,\n",
    "  verbose=1,\n",
    "  validation_split=0.2,\n",
    "  callbacks = [EarlyStopping(monitor='val_loss', patience=1)],     \n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/exacon03/Jupyter/Kerasmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input a sentence to be evaluated, or Enter to quit: bad\n",
      "Sentiment: Negative  Confidence Level: 47 %\n"
     ]
    }
   ],
   "source": [
    "while 1:\n",
    "    evalSentence =input('Input a sentence to be evaluated, or Enter to quit: ')\n",
    "\n",
    "    if len(evalSentence) == 0:\n",
    "        break\n",
    "\n",
    "    # Format your input for the neural net\n",
    "    evalSentence=[evalSentence]\n",
    "    tx = vectorizer.transform(evalSentence).astype('float32')\n",
    "    tx = selector.transform(tx).astype('float32')\n",
    "    pred = model.predict(tx)\n",
    "    if pred[0][0]>0.5:\n",
    "        print(\"Sentiment: Positive  Confidence Level:\",int(np.round((pred[0][0]-0.5)*200)),\"%\")\n",
    "    else:\n",
    "        print(\"Sentiment: Negative  Confidence Level:\",int(np.round((0.5-pred[0][0])*200)),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_for_production(model, \"1\", \"/home/exacon03/Jupyter/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
